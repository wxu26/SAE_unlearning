{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6628e3e-fa76-48fe-bc46-e544388613ed",
   "metadata": {},
   "source": [
    "# Performance statistics for the model and the SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c97cc7fd-a115-4d86-8a9b-c6f9ee325875",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes of train, val, test = 1003862, 55778, 55778\n",
      "vocab size = 66, unique chars:\n",
      "['\\n', ' ', '!', '\"', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import model_data, TransformerModel, generate_from_model, validation\n",
    "from SAE import config_default, TransformerWithSAE\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22838d41-15d9-44d6-a7bf-b2a525362446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TransformerModel()\n",
    "model.to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"model.10000.pth\"))\n",
    "\n",
    "modelL3 = TransformerWithSAE()\n",
    "modelL3.layer_for_SAE = 3\n",
    "modelL3.to(DEVICE)\n",
    "modelL3.load_state_dict(torch.load(\"SAE_L3.10000.pth\"))\n",
    "modelL3.update_scale_factor()\n",
    "\n",
    "modelL6 = TransformerWithSAE()\n",
    "modelL6.layer_for_SAE = 6\n",
    "modelL6.to(DEVICE)\n",
    "modelL6.load_state_dict(torch.load(\"SAE_L6.10000.pth\"))\n",
    "modelL6.update_scale_factor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "686d5c4a-e8e5-4058-9d71-8a96512ad5e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_performance(model, SAE = False):\n",
    "    model.eval()\n",
    "    batch_size = 1024\n",
    "    out = ''\n",
    "    # corss entropy loss\n",
    "    x, y = model_data.draw(batch_size,'test')\n",
    "    res = model(x, y)\n",
    "    logits = res[0]\n",
    "    loss = res[-1].item()\n",
    "    out += f\"loss={loss:.4f}\"\n",
    "    # accuracy\n",
    "    probs = F.softmax(logits, dim=-1).view(-1,logits.shape[-1])\n",
    "    y_pred = torch.multinomial(probs, num_samples=1)[:,0]\n",
    "    acc = torch.mean(y.view(-1)==y_pred, dtype=float)\n",
    "    out += f\";    accuracy={acc:.4f}\"\n",
    "    # SAE L2 loss\n",
    "    if SAE:\n",
    "        model.lam = 0 # only output L2 loss\n",
    "        features, loss = model(x, y, SAE_loss=True)\n",
    "        loss = loss.item()\n",
    "        out += f\";    SAE relative L2 loss={loss/x.shape[-1]:.4f}\" #has been normalized to ||x||^2 = n_model\n",
    "        n_dead = torch.sum(torch.mean(features, dim=(0,1))>0, dtype=int)\n",
    "        out += f\";    {features.shape[-1]-n_dead} dead features\"\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4716e7ca-3fd9-404f-bfa9-b1a08a22c411",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=1.6420;    accuracy=0.4525\n",
      "loss=1.7451;    accuracy=0.4301;    SAE relative L2 loss=0.0217;    1017 dead features\n",
      "loss=1.7840;    accuracy=0.4320;    SAE relative L2 loss=0.0980;    2 dead features\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "test_performance(model)\n",
    "test_performance(modelL3, SAE=True)\n",
    "test_performance(modelL6, SAE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfdf7831-b340-4f59-a99f-cb4eff2bf35d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9204035874439461"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.6420/1.7451\n",
    "1.6420/1.7840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8474acfb-857c-4a86-99ba-2acd3260dba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m your duty throughly, I advise you:\n",
      "Imagine 'twere the right Vincentio.\n",
      "\n",
      "BIONDELLO:\n",
      "Tut, fear not me.\n",
      "\n",
      "TRANIO:\n",
      "But hast thou done thy errand to Baptista?\n",
      "\n",
      "BIONDELLO:\n",
      "I told him that your father was at Venice,\n",
      "And that you look'd for him this day in Padua.\n",
      "\u001b[0mI'll thee talk, am friends that stand that will the\n",
      "He left, he waked his brother's pardon, is the sback.\n",
      "\n",
      "JULIET:\n",
      "This blood England,\n",
      "And being madam.\n",
      "\n",
      "YORK:\n",
      "Or love boy:\n",
      "O come, give me,\n",
      "Those against overboke. Come, mulder will with the love;\n",
      "If we do king up, I'll we done it you is it.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "The do's a crown?\n",
      "Give me impen tribunes, you leave you;\n",
      "I have shaw you made in the come.\n",
      "\n",
      "GLOUCESTER:\n",
      "And more him Clifford; will I tell you to me.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "LADY ANNE:\n",
      "Why, call my lord.\n",
      "\n",
      "GLOUCEST\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "_ = generate_from_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda3e428-bad1-4a98-bf3c-58ac1a29709d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
